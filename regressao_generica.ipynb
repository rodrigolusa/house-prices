{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "k77xaJfA-epq"
   },
   "outputs": [],
   "source": [
    "# %matplotlib inline\n",
    "# from IPython.display import HTML\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "#import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cost(thetas, x, y):\n",
    "    \"\"\"\n",
    "    Calcula o erro quadratico medio\n",
    "    \n",
    "    Args:\n",
    "        theta_0 (float): intercepto da reta \n",
    "        theta_1 (float): inclinacao da reta\n",
    "        data (np.array): matriz com o conjunto de dados, x na coluna 0 e y na coluna 1\n",
    "    \n",
    "    Retorna:\n",
    "        float: o erro quadratico medio\n",
    "    \"\"\"\n",
    "    total_cost = 0\n",
    "    sum_ = np.sum(np.square((thetas[0] + np.sum(np.dot(thetas[1:].T, x.T))) - y))\n",
    "        \n",
    "    total_cost = sum_/y.shape[0]\n",
    "\n",
    "    return total_cost\n",
    "\n",
    "\n",
    "def get_min_max(x):\n",
    "    minimo = x.min()\n",
    "    maximo = x.max()\n",
    "    amplitude = maximo - minimo\n",
    "    x = (x - minimo) / amplitude\n",
    "    return x\n",
    "\n",
    "\n",
    "def get_derivada(x, y, thetas, derivada_theta):\n",
    "    derivada_funcao_erro = thetas[0] + np.dot(thetas[1:].T , x.T) - y\n",
    "    return (2/x.shape[0]) * np.sum(derivada_funcao_erro * derivada_theta)\n",
    "\n",
    "\n",
    "def step_gradient(thetas_current, x, y, alpha):\n",
    "    \"\"\"Calcula um passo em direção ao EQM mínimo\n",
    "    \n",
    "    Args:\n",
    "        theta_0_current (float): valor atual de theta_0\n",
    "        theta_1_current (float): valor atual de theta_1\n",
    "        data (np.array): vetor com dados de treinamento (x,y)\n",
    "        alpha (float): taxa de aprendizado / tamanho do passo \n",
    "    \n",
    "    Retorna:\n",
    "        tupla: (theta_0, theta_1) os novos valores de theta_0, theta_1\n",
    "    \"\"\"\n",
    "    thetas_updated = []\n",
    "    for indice in range(thetas_current.shape[0]):\n",
    "        if indice:\n",
    "            derivada_theta = 1\n",
    "        else:\n",
    "            derivada_theta = x[:, indice]\n",
    "        derivada = get_derivada(x, y, thetas_current, derivada_theta)\n",
    "        theta_updated = thetas_current[indice] - (alpha * derivada)\n",
    "        thetas_updated.append(theta_updated)        \n",
    "    return np.array(thetas_updated).reshape(len(thetas_updated), 1)\n",
    "\n",
    "def gradient_descent(x, y, starting_thetas=None, learning_rate=0.0001, num_iterations=10):\n",
    "    \"\"\"executa a descida do gradiente\n",
    "    \n",
    "    Args:\n",
    "        data (np.array): dados de treinamento, x na coluna 0 e y na coluna 1\n",
    "        starting_theta_0 (float): valor inicial de theta0 \n",
    "        starting_theta_1 (float): valor inicial de theta1\n",
    "        learning_rate (float): hyperparâmetro para ajustar o tamanho do passo durante a descida do gradiente\n",
    "        num_iterations (int): hyperparâmetro que decide o número de iterações que cada descida de gradiente irá executar\n",
    "    \n",
    "    Retorna:\n",
    "        list : os primeiros dois parâmetros são o Theta0 e Theta1, que armazena o melhor ajuste da curva. O terceiro e quarto parâmetro, são vetores com o histórico dos valores para Theta0 e Theta1.\n",
    "    \"\"\"\n",
    "\n",
    "    # valores iniciais\n",
    "    if starting_thetas:\n",
    "        thetas = np.array(starting_thetas).reshape(x.shape[1]+1, 1)\n",
    "    else:\n",
    "        thetas = np.zeros(x.shape[1]+1).reshape(x.shape[1]+1, 1)\n",
    "    \n",
    "    # variável para armazenar o custo ao final de cada step_gradient\n",
    "    cost_graph = []\n",
    "    \n",
    "    # vetores para armazenar os valores de Theta0 e Theta1 apos cada iteração de step_gradient (pred = Theta1*x + Theta0)\n",
    "    thetas_progress = []\n",
    "    \n",
    "    # Para cada iteração, obtem novos (Theta0,Theta1) e calcula o custo (EQM)\n",
    "    num_iterations = num_iterations\n",
    "    for i in range(num_iterations):\n",
    "        cost = compute_cost(thetas, x, y)\n",
    "        cost_graph.append(cost)\n",
    "        thetas = step_gradient(thetas, x, y, alpha=learning_rate)\n",
    "        #print(thetas)\n",
    "        thetas_progress.append(thetas)\n",
    "        \n",
    "    return thetas, cost_graph, np.array(thetas_progress).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "atributos_1 = [\"GrLivArea\", \"SalePrice\"]\n",
    "atributos_2 = [\"GrLivArea\", \"OverallQual\", \"SalePrice\"]\n",
    "atributos_3 = [\"GrLivArea\", \"OverallQual\", \"OverallCond\", \"GarageArea\", \"YearBuilt\", \"SalePrice\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Theta_0 otimizado:  1.0573310728603653e-05\n",
      "Theta_1 otimizado:  4.055387013484685e-05\n",
      "Custo minimizado:  0.04810675512793792\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\"data/house_prices_train.csv\")[atributos_1]\n",
    "x = data.iloc[:,:-1].astype(\"float\").values\n",
    "y = data.iloc[:,-1].astype(\"float\").values\n",
    "\n",
    "for i in range(data.shape[1]-1):\n",
    "    x[:,i] = get_min_max(x[:,i])\n",
    "y = get_min_max(y)\n",
    "\n",
    "thetas, cost_graph, thetas_progres = gradient_descent(x, y, learning_rate=0.000001, num_iterations=100)\n",
    "\n",
    "# #Imprimir parâmetros otimizados\n",
    "for index, theta in enumerate(thetas):\n",
    "    print (f'Theta_{index} otimizado: ', theta[0])\n",
    "\n",
    "# #Imprimir erro com os parâmetros otimizados\n",
    "print ('Custo minimizado: ', compute_cost(thetas, x, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Theta_0 otimizado:  1.0572768241334009e-05\n",
      "Theta_1 otimizado:  4.055159548398755e-05\n",
      "Theta_2 otimizado:  4.055159548398755e-05\n",
      "Custo minimizado:  0.036512622436602866\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\"data/house_prices_train.csv\")[atributos_2]\n",
    "x = data.iloc[:,:-1].astype(\"float\").values\n",
    "y = data.iloc[:,-1].astype(\"float\").values\n",
    "\n",
    "for i in range(data.shape[1]-1):\n",
    "    x[:,i] = get_min_max(x[:,i])\n",
    "y = get_min_max(y)\n",
    "\n",
    "thetas, cost_graph, thetas_progres = gradient_descent(x, y, learning_rate=0.000001, num_iterations=100)\n",
    "\n",
    "# #Imprimir parâmetros otimizados\n",
    "for index, theta in enumerate(thetas):\n",
    "    print (f'Theta_{index} otimizado: ', theta[0])\n",
    "\n",
    "# #Imprimir erro com os parâmetros otimizados\n",
    "print ('Custo minimizado: ', compute_cost(thetas, x, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Theta_0 otimizado:  1.0571275579870783e-05\n",
      "Theta_1 otimizado:  4.054507342796464e-05\n",
      "Theta_2 otimizado:  4.054507342796464e-05\n",
      "Theta_3 otimizado:  4.054507342796464e-05\n",
      "Theta_4 otimizado:  4.054507342796464e-05\n",
      "Theta_5 otimizado:  4.054507342796464e-05\n",
      "Custo minimizado:  0.015747054774088456\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\"data/house_prices_train.csv\")[atributos_3]\n",
    "x = data.iloc[:,:-1].astype(\"float\").values\n",
    "y = data.iloc[:,-1].astype(\"float\").values\n",
    "\n",
    "for i in range(data.shape[1]-1):\n",
    "    x[:,i] = get_min_max(x[:,i])\n",
    "y = get_min_max(y)\n",
    "\n",
    "thetas, cost_graph, thetas_progres = gradient_descent(x, y, learning_rate=0.000001, num_iterations=100)\n",
    "\n",
    "# #Imprimir parâmetros otimizados\n",
    "for index, theta in enumerate(thetas):\n",
    "    print (f'Theta_{index} otimizado: ', theta[0])\n",
    "\n",
    "# #Imprimir erro com os parâmetros otimizados\n",
    "print ('Custo minimizado: ', compute_cost(thetas, x, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "Cors83rQB-AX"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(cost_graph)\n",
    "plt.xlabel('No. de interações')\n",
    "plt.ylabel('Custo')\n",
    "plt.title('Custo por iteração')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "treino-regressao-linear.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
